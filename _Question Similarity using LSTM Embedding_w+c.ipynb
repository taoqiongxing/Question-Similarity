{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('C:/Users/Ax/Desktop/w+c/train.csv', encoding='utf-8')\n",
    "df_train['id'] = df_train['id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('C:/Users/Ax/Desktop/w+c/test.csv', encoding='utf-8')\n",
    "df_test['test_id'] = df_test['test_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat((df_train, df_test),sort=True)\n",
    "df_all['question1'].fillna('', inplace=True)\n",
    "df_all['question2'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
    "of pandas will change to not sort by default.\n",
    "\n",
    "To accept the future behavior, pass 'sort=True'.\n",
    "\n",
    "To retain the current behavior and silence the warning, pass sort=False\n",
    "\n",
    "  \"\"\"Entry point for launching an IPython kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_vectorizer = CountVectorizer(max_features=10000-1).fit(\n",
    "    itertools.chain(df_all['question1'], df_all['question2']))\n",
    "other_index = len(counts_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tokenizer = re.compile(counts_vectorizer.token_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padded_seqs(texts, max_len=30):\n",
    "    seqs = texts.apply(lambda s: \n",
    "        [counts_vectorizer.vocabulary_[w] if w in counts_vectorizer.vocabulary_ else other_index\n",
    "         for w in words_tokenizer.findall(s.lower())])\n",
    "    return pad_sequences(seqs, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all = df_all.sample(1000) # Just for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_val, X2_train, X2_val, y_train, y_val = \\\n",
    "    train_test_split(create_padded_seqs(df_all[df_all['id'].notnull()]['question1']), \n",
    "                     create_padded_seqs(df_all[df_all['id'].notnull()]['question2']),\n",
    "                     df_all[df_all['id'].notnull()]['is_duplicate'].values,\n",
    "                     stratify=df_all[df_all['id'].notnull()]['is_duplicate'].values,\n",
    "                     test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as lyr\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 30, 300)      3000000     input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 256)          570368      embedding_3[0][0]                \n",
      "                                                                 embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 256)          0           lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           4112        multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            17          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,574,497\n",
      "Trainable params: 3,574,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1_tensor = lyr.Input(X1_train.shape[1:])\n",
    "input2_tensor = lyr.Input(X2_train.shape[1:])\n",
    "\n",
    "words_embedding_layer = lyr.Embedding(X1_train.max() + 1, 300)\n",
    "seq_embedding_layer = lyr.LSTM(256, activation='tanh')\n",
    "\n",
    "seq_embedding = lambda tensor: seq_embedding_layer(words_embedding_layer(tensor))\n",
    "\n",
    "merge_layer = lyr.multiply([seq_embedding(input1_tensor), seq_embedding(input2_tensor)])\n",
    "\n",
    "dense1_layer = lyr.Dense(16, activation='sigmoid')(merge_layer)\n",
    "\n",
    "ouput_layer = lyr.Dense(1, activation='sigmoid')(dense1_layer)\n",
    "\n",
    "model = Model([input1_tensor, input2_tensor], ouput_layer)\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 228947 samples, validate on 25439 samples\n",
      "Epoch 1/50\n",
      " - 241s - loss: 0.1318 - val_loss: 0.1525\n",
      "Epoch 2/50\n",
      " - 242s - loss: 0.1292 - val_loss: 0.1485\n",
      "Epoch 3/50\n",
      " - 241s - loss: 0.1272 - val_loss: 0.1477\n",
      "Epoch 4/50\n",
      " - 242s - loss: 0.1239 - val_loss: 0.1482\n",
      "Epoch 5/50\n",
      " - 241s - loss: 0.1213 - val_loss: 0.1437\n",
      "Epoch 6/50\n",
      " - 243s - loss: 0.1193 - val_loss: 0.1427\n",
      "Epoch 7/50\n",
      " - 241s - loss: 0.1160 - val_loss: 0.1393\n",
      "Epoch 8/50\n",
      " - 245s - loss: 0.1148 - val_loss: 0.1413\n",
      "Epoch 9/50\n",
      " - 244s - loss: 0.1118 - val_loss: 0.1401\n",
      "Epoch 10/50\n",
      " - 242s - loss: 0.1101 - val_loss: 0.1379\n",
      "Epoch 11/50\n",
      " - 243s - loss: 0.1071 - val_loss: 0.1381\n",
      "Epoch 12/50\n",
      " - 245s - loss: 0.1065 - val_loss: 0.1356\n",
      "Epoch 13/50\n",
      " - 240s - loss: 0.1057 - val_loss: 0.1357\n",
      "Epoch 14/50\n",
      " - 240s - loss: 0.1038 - val_loss: 0.1356\n",
      "Epoch 15/50\n",
      " - 241s - loss: 0.1036 - val_loss: 0.1335\n",
      "Epoch 16/50\n",
      " - 241s - loss: 0.1024 - val_loss: 0.1327\n",
      "Epoch 17/50\n",
      " - 240s - loss: 0.1012 - val_loss: 0.1319\n",
      "Epoch 18/50\n",
      " - 243s - loss: 0.0996 - val_loss: 0.1338\n",
      "Epoch 19/50\n",
      " - 244s - loss: 0.0991 - val_loss: 0.1321\n",
      "Epoch 20/50\n",
      " - 241s - loss: 0.0983 - val_loss: 0.1299\n",
      "Epoch 21/50\n",
      " - 245s - loss: 0.0975 - val_loss: 0.1289\n",
      "Epoch 22/50\n",
      " - 252s - loss: 0.0987 - val_loss: 0.1290\n",
      "Epoch 23/50\n",
      " - 252s - loss: 0.0974 - val_loss: 0.1308\n",
      "Epoch 24/50\n",
      " - 246s - loss: 0.0959 - val_loss: 0.1291\n",
      "Epoch 25/50\n",
      " - 242s - loss: 0.0951 - val_loss: 0.1280\n",
      "Epoch 26/50\n",
      " - 242s - loss: 0.0945 - val_loss: 0.1284\n",
      "Epoch 27/50\n",
      " - 241s - loss: 0.0933 - val_loss: 0.1272\n",
      "Epoch 28/50\n",
      " - 241s - loss: 0.0926 - val_loss: 0.1255\n",
      "Epoch 29/50\n",
      " - 241s - loss: 0.0922 - val_loss: 0.1278\n",
      "Epoch 30/50\n",
      " - 242s - loss: 0.0922 - val_loss: 0.1271\n",
      "Epoch 31/50\n",
      " - 243s - loss: 0.0908 - val_loss: 0.1280\n",
      "Epoch 32/50\n",
      " - 242s - loss: 0.0902 - val_loss: 0.1239\n",
      "Epoch 33/50\n",
      " - 243s - loss: 0.0896 - val_loss: 0.1249\n",
      "Epoch 34/50\n",
      " - 245s - loss: 0.0895 - val_loss: 0.1285\n",
      "Epoch 35/50\n",
      " - 243s - loss: 0.0902 - val_loss: 0.1252\n",
      "Epoch 36/50\n",
      " - 243s - loss: 0.0898 - val_loss: 0.1251\n",
      "Epoch 37/50\n",
      " - 243s - loss: 0.0900 - val_loss: 0.1276\n",
      "Epoch 38/50\n",
      " - 242s - loss: 0.0892 - val_loss: 0.1243\n",
      "Epoch 39/50\n",
      " - 242s - loss: 0.0886 - val_loss: 0.1239\n",
      "Epoch 40/50\n",
      " - 240s - loss: 0.0891 - val_loss: 0.1253\n",
      "Epoch 41/50\n",
      " - 240s - loss: 0.0888 - val_loss: 0.1241\n",
      "Epoch 42/50\n",
      " - 246s - loss: 0.0875 - val_loss: 0.1229\n",
      "Epoch 43/50\n",
      " - 250s - loss: 0.0869 - val_loss: 0.1244\n",
      "Epoch 44/50\n",
      " - 248s - loss: 0.0876 - val_loss: 0.1219\n",
      "Epoch 45/50\n",
      " - 249s - loss: 0.0870 - val_loss: 0.1257\n",
      "Epoch 46/50\n",
      " - 249s - loss: 0.0877 - val_loss: 0.1236\n",
      "Epoch 47/50\n",
      " - 243s - loss: 0.0869 - val_loss: 0.1243\n",
      "Epoch 48/50\n",
      " - 242s - loss: 0.0868 - val_loss: 0.1246\n",
      "Epoch 49/50\n",
      " - 240s - loss: 0.0871 - val_loss: 0.1251\n",
      "Epoch 50/50\n",
      " - 245s - loss: 0.0870 - val_loss: 0.1248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e915e2ea20>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X1_train, X2_train], y_train, \n",
    "          validation_data=([X1_val, X2_val], y_val), \n",
    "          batch_size=64, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model = Model([input1_tensor, input2_tensor], merge_layer)\n",
    "features_model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_train = features_model.predict([X1_train, X2_train], batch_size=64)\n",
    "F_val = features_model.predict([X1_val, X2_val], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dTrain = xgb.DMatrix(F_train, label=y_train)\n",
    "dVal = xgb.DMatrix(F_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.663084\tval-logloss:0.664789\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 10 rounds.\n",
      "[10]\ttrain-logloss:0.483338\tval-logloss:0.499586\n",
      "[20]\ttrain-logloss:0.398336\tval-logloss:0.425103\n",
      "[30]\ttrain-logloss:0.354167\tval-logloss:0.390077\n",
      "[40]\ttrain-logloss:0.325369\tval-logloss:0.368962\n",
      "[50]\ttrain-logloss:0.3013\tval-logloss:0.351457\n",
      "[60]\ttrain-logloss:0.285441\tval-logloss:0.341443\n",
      "[70]\ttrain-logloss:0.270521\tval-logloss:0.331945\n",
      "[80]\ttrain-logloss:0.260629\tval-logloss:0.327028\n",
      "[90]\ttrain-logloss:0.252897\tval-logloss:0.323291\n",
      "[100]\ttrain-logloss:0.244436\tval-logloss:0.319482\n",
      "[110]\ttrain-logloss:0.237146\tval-logloss:0.316682\n",
      "[120]\ttrain-logloss:0.230382\tval-logloss:0.31428\n",
      "[130]\ttrain-logloss:0.225529\tval-logloss:0.31287\n",
      "[140]\ttrain-logloss:0.220674\tval-logloss:0.310984\n",
      "[150]\ttrain-logloss:0.216543\tval-logloss:0.309383\n",
      "[160]\ttrain-logloss:0.212714\tval-logloss:0.30831\n",
      "[170]\ttrain-logloss:0.208537\tval-logloss:0.307244\n",
      "[180]\ttrain-logloss:0.204823\tval-logloss:0.306317\n",
      "[190]\ttrain-logloss:0.201833\tval-logloss:0.305734\n",
      "[200]\ttrain-logloss:0.198716\tval-logloss:0.305123\n",
      "[210]\ttrain-logloss:0.19549\tval-logloss:0.304729\n",
      "[220]\ttrain-logloss:0.193163\tval-logloss:0.304309\n",
      "[230]\ttrain-logloss:0.190684\tval-logloss:0.303985\n",
      "[240]\ttrain-logloss:0.188666\tval-logloss:0.303699\n",
      "[250]\ttrain-logloss:0.186313\tval-logloss:0.303522\n",
      "[260]\ttrain-logloss:0.18422\tval-logloss:0.303239\n",
      "[270]\ttrain-logloss:0.182364\tval-logloss:0.30317\n",
      "[280]\ttrain-logloss:0.1802\tval-logloss:0.302711\n",
      "[290]\ttrain-logloss:0.178576\tval-logloss:0.302556\n",
      "[300]\ttrain-logloss:0.176959\tval-logloss:0.302434\n",
      "Stopping. Best iteration:\n",
      "[298]\ttrain-logloss:0.177284\tval-logloss:0.302353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'booster': 'gbtree',\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 9,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 1 / F_train.shape[1]**0.5,\n",
    "    'min_child_weight': 5,\n",
    "    'silent': 1\n",
    "}\n",
    "bst = xgb.train(xgb_params, dTrain, 1000,  [(dTrain,'train'), (dVal,'val')], \n",
    "                verbose_eval=10, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = create_padded_seqs(df_all[df_all['test_id'].notnull()]['question1'])\n",
    "X2_test = create_padded_seqs(df_all[df_all['test_id'].notnull()]['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_test = features_model.predict([X1_test, X2_test], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dTest = xgb.DMatrix(F_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({\n",
    "        'test_id': df_all[df_all['test_id'].notnull()]['test_id'].values,\n",
    "        'y_pre': bst.predict(dTest, ntree_limit=bst.best_ntree_limit)\n",
    "    }).set_index('test_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.410701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.907897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.102319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.974736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_pre\n",
       "test_id          \n",
       "0        0.410701\n",
       "1        0.907897\n",
       "2        0.102319\n",
       "3        0.974736\n",
       "4        0.080133"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e80ed00cf8>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sub['y_pre'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission20180624LSTM_w+c_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
